### 消息队列使用场景（解耦、异步、削峰）

1.解耦：

​    订单业务会对接很多的其他系统， 每次创建订单都需要通知他们，每次新接入一个系统总不能都要维护并添加一遍通知逻辑么？所以采用消息队列，每次订单创建后都将订单信息发布到消息队列，这样其他系统谁想要谁就自己去消费订阅

2.异步：

​    系统有app、erp消息、站内信、短信等推送信息业务，推送时相关处理会有好几秒，比较耗时又占用资源，并且实时性要求并不高，所以采用消息队列存入需要推送的消息，并异步去消费消息，执行相关推送信息业务

3.削峰：

​    由于是b2b行业，每次到月底会有结算换做优惠券发放的一个业务场景，会有大批量的优惠券需要发放存入数据库，造成并发写入数据库数据暴增，造成压力，但是平时发券又不会有那么大的数据量，所以采用消息队列的方式，先将发放优惠券信息存入消息队列，这种短暂积压是可以接受的，然后再以每秒2000左右的消费频率进行消费写入数据库，达到消除高峰期数据库压力的问题



### 消息队列的技术选型：

​	由于公司对技术架构并没有那么大的研发实力，所以首先要考虑社区活跃度高的，技术挑战不大的，对于业务量及可用性来讲，目前RabbitMQ基于主从镜像集群模式的高可用方案也是完全可以支撑的，也就选择了RabbitMQ

主从集群高可用：ActiveMQ、RabbitMQ

分布式高可用：RocketMQ、Kafka



### 消息如何避免重复消费

​	其实换句话说，消息队列无论如何优化，都是有可能存在重复消费的情况，那么这个问题就转化成了如何保证幂等性，例如Kafka中会有个offset的概念，每个消息都有个offset值，当消费端消费后会把自身消费到的offset提交给注册中心，但是这时如果强制重启了，恢复正常后offset没有提交成功，再去消费就会出现重复消费的情况。

​	如何保证幂等性呢，需要结合业务考虑，

​		1.通用的可以把每次消息生成一个唯一ID，然后消费了就存入redis，每次去查询redis是否包含这个id，来决定是否执行

​		2.为了考虑性能，还可以是生产者生产消息的时候先将id放入redis，然后消费的时候去删除这个id（删除效率比查询高很多），不为-1就是存在这个id，可以进行消费



### 消息如何防止数据丢失

#### RabbitMQ数据丢失会出现3种情况

1. 生产者

   将数据发送给MQ路途中丢失了，可以采用两种办法

   * （同步）发送数据前开启RabbitMQ事务`channel.txSelect`
   * （异步）生产者设置`confirm`模式，每次写消息会分配一个唯一ID，发送消息后会有个回调，写入成功回调`ack` 失败回调`nack`都可以处理

2. MQ

   防止RabbitMQ自己挂了而丢失消息内容，设置RabbitMQ持久化方案

   * 创建queue的时候将其设置为持久化，这样只是保证queue的元数据被持久化
   * 发送消息的时候将消息的`deliveryMode`设置为2，这样才会将消息内容持久化

   就算持久化也有可能还没持久化到磁盘就挂了，所以还需要结合生产者的`confirm`,只有持久化到磁盘后再`ack`才能保证RabbitMQ持久化成功不丢失数据

3. 消费者

   刚消费到，但是还没有处理就挂了，就会造成还没真正消费就被RabbitMQ认为已经消费了

   * 结合RabbitMQ的`ack`机制，关闭RabbitMQ的自动`ack`，当消费者真正处理完之后程序中再去自行处理`ack`

#### Kafka数据丢失情况

1. 生产者

   将数据发送给Kafka，但是还没有接收到就丢失了

   * producer端设置`acks=all`,要求Kafka写入所有的partition后才认为已经发送成功
   * producer端设置`retries=999`,一旦写入失败就进行多少次的重试写入

2. Kafka服务端

   还没有写入就丢失了，基于Kafka本身是没有使用内存作为缓存而是将消息持久化存入文件中的，所以不考虑没写而是应该考虑没有写入所有的partition，因为他有很多的备份

   * 给topic设置`replication.factor`参数必须大于1，要求每个partition必须有至少2个副本

   * Kafka服务端设置`min.insync.replicas`参数必须大于1，这个是要求leader至少感知一个follower跟自己联系，没有掉队，才能保证leader挂了还有一个follower

3. 消费者

   Kafka有offset概念，消费端可能刚获取消息还没有提交自己消费的offset就挂了

   * 关闭Kafka自动提交offset，消费者完成消费手动提交offset



### 消息如何保证顺序性

总的来说消息队列中间件本身都是有序进行存储的，但是消费时多个消费者去消费消息的处理完成时间都会不一定，会造成乱序，所以必须是仅一个消费者去有序消费才可以

* RabbitMQ：必须是同一个queue中，并且只能被一个消费者消费（多线程消费其实也是要考虑将有序的消息分组到同一个内存队列中，每个线程负责一个队列进行消费）

* Kafka：必须是同一个topic，同一个partition，只能被一个消费者消费

